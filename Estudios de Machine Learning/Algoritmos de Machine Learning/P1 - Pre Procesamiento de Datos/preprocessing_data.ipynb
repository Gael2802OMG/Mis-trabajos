{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando Librerías\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configurando Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando el Dataset\n",
    "dataset = pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrando una fracción del dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary\n",
       "0   France  44.0  72000.0\n",
       "1    Spain  27.0  48000.0\n",
       "2  Germany  30.0  54000.0\n",
       "3    Spain  38.0  61000.0\n",
       "4  Germany  40.0      NaN\n",
       "5   France  35.0  58000.0\n",
       "6    Spain   NaN  52000.0\n",
       "7   France  48.0  79000.0\n",
       "8  Germany  50.0  83000.0\n",
       "9   France  37.0  67000.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obteniendo datos de X\n",
    "X = dataset.drop('Purchased',axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     No\n",
       "1    Yes\n",
       "2     No\n",
       "3     No\n",
       "4    Yes\n",
       "5    Yes\n",
       "6     No\n",
       "7    Yes\n",
       "8     No\n",
       "9    Yes\n",
       "Name: Purchased, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obteniendo datos de Y\n",
    "y = dataset.pop('Purchased')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando dimensiones de X e y\n",
    "\n",
    "print('X',X.shape)\n",
    "print('y',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando los datos NaN\n",
    "\n",
    "# Estructurando el imputer para que reemplace los NaN por la media de cada columna \n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# Procesando el conjunto de X\n",
    "imputer = imputer.fit(X.iloc[:, 1:3])\n",
    "X.iloc[:, 1:3] = imputer.transform(X.iloc[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando el conjunto de X con sus NaN reemplazados \n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codificar Datos Categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencorer = LabelEncoder()\n",
    "X.iloc[:,0] = labelencorer.fit_transform(X.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando la transformación categorica\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "La razón de transformar estos datos <b>categoricos ('Strings')</b> a datos <b>numericos ('Integer', 'Float')</b>, es por que a la hora de entrenar un conjunto de datos, nuestra red neuronal no puede procesar datos tipo string de forma sencilla. Es por esta razón por la que se decide realizar esta transformación con ayuda de Sklearn. Por lo que los datos <b>['France', 'Spain', 'Germany']</b>, pasan a ser <b>[0, 2, 1]</b><br>\n",
    "</p>\n",
    "<p style='text-align: justify;'>\n",
    "Esto es una buena solución para poder procesar los datos a travez de una red neuronal. Sin embargo esta transformación daría a entender a la red neuronal que los datos tienen una relación de <b>[menor, medio y mayor]</b>, y como pueden ver esta representación aún que ya no es en string sigue siendo erronea por que los países no tienen correlaciones entre sí, como las prendas de ropa que tienen medidas <b>(CH, M, L)</b>, en este caso si tienen una relación de medidas para las prendas de ropa y en este caso si sería correcto esta solución.<br>\n",
    "</p>\n",
    "<p style='text-align: justify;'>\n",
    "Por lo tanto para tener una solución mucho más correcta utilizaremos unos tipos de datos especiales, llamados <b>Dummy</b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfomrmación a Variables Dummy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct = ColumnTransformer([('one_hot_encoder', OneHotEncoder(categories='auto'),[0])],remainder='passthrough')\n",
    "\n",
    "X = np.array(ct.fit_transform(X), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1,     0,     0,    44, 72000],\n",
       "       [    0,     0,     1,    27, 48000],\n",
       "       [    0,     1,     0,    30, 54000],\n",
       "       [    0,     0,     1,    38, 61000],\n",
       "       [    0,     1,     0,    40, 63777],\n",
       "       [    1,     0,     0,    35, 58000],\n",
       "       [    0,     0,     1,    38, 52000],\n",
       "       [    1,     0,     0,    48, 79000],\n",
       "       [    0,     1,     0,    50, 83000],\n",
       "       [    1,     0,     0,    37, 67000]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "Como pueden ver en la impresión anterior separamos la lista de paises en 3 columnas, una por cada tipo de categoría que se encontró en esa columna, dichas columnas solo tendrán un <b>1</b> para especificar que en esa fila se encuentra dicha categoría, por otro lado, se pondrá un <b>0</b> para representar que en esa fila no se encuentra dicha categoría \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando valores de Y\n",
    "\n",
    "y = labelencorer.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividir el dataset en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train: [[    0     1     0    40 63777]\n",
      " [    1     0     0    37 67000]\n",
      " [    0     0     1    27 48000]\n",
      " [    0     0     1    38 52000]\n",
      " [    1     0     0    48 79000]\n",
      " [    0     0     1    38 61000]\n",
      " [    1     0     0    44 72000]\n",
      " [    1     0     0    35 58000]]\n",
      "----------------------\n",
      "X test [[    0     1     0    30 54000]\n",
      " [    0     1     0    50 83000]]\n",
      "----------------------\n",
      "y train [1 1 1 0 1 0 0 1]\n",
      "----------------------\n",
      "y test [0 0]\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "print('X train:',X_train)\n",
    "print('----------------------')\n",
    "print('X test',X_test)\n",
    "print('----------------------')\n",
    "print('y train',y_train)\n",
    "print('----------------------')\n",
    "print('y test',y_test)\n",
    "print('----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Escalado de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "En este apartado se utilizará una tecnica para poder escalar los datos, el escalado de datos es utilizado para poder establecer un margen de valores para todas las columnas que se vallan a utilizar en el dataframe de entrenamiento y testing.<br>\n",
    "</p>\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "Este metodo es utilizado solamente para casos muy especificos en los que las columnas de datos que queremos procesar tienen una discrepancia muy grande entre ellas, en este caso siendo <b>['Age', 'Salary']</b>, estos datos son muy importantes para ser usados en nuestro conjunto de datos, sin embargo estos datos tienen magnitudes muy diferentes entre sí, por lo que la computadora podría tener problemas para relacionar unas con la sotras, ya que el salario se muestre en miles de unidades y los años en tansolo decenas.<br>\n",
    "</p>\n",
    "<p style='text-align: justify;'>\n",
    "Por esta razón se escalarán los datos, y para esta tarea contamos con dos formas diferentes de escalar los datos. Podemos <b>Normalizar</b> los datos, lo que significa que debemos distribuir los valores de una columna entre el -1 y el 1, Esta es una buena forma de escalado para los datos, aún que en esta ocación utilizaremos la <b>Estandarización</b> de datos, siendo esta como su nombre lo dice, sacar la desviación estandar en los datos y utilizarlo para el escalado de los datos, esto en su mayoría puede ser mucho mejor que simplemente convertir los datos de -1 a 1, ya que los datos son escalados de tal forma que preservar cierta escencia de los datos originales.<br>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train: [[-1.          2.64575131 -0.77459667  0.27978024  0.12374357]\n",
      " [ 1.         -0.37796447 -0.77459667 -0.23673712  0.4617671 ]\n",
      " [-1.         -0.37796447  1.29099445 -1.95846165 -1.53092514]\n",
      " [-1.         -0.37796447  1.29099445 -0.06456467 -1.11141099]\n",
      " [ 1.         -0.37796447 -0.77459667  1.65715986  1.72030956]\n",
      " [-1.         -0.37796447  1.29099445 -0.06456467 -0.16750414]\n",
      " [ 1.         -0.37796447 -0.77459667  0.96847005  0.98615979]\n",
      " [ 1.         -0.37796447 -0.77459667 -0.58108203 -0.48213975]]\n",
      "---------------------------------------\n",
      "X test: [[-1.          2.64575131 -0.77459667 -1.44194429 -0.90165391]\n",
      " [-1.          2.64575131 -0.77459667  2.00150476  2.13982372]]\n"
     ]
    }
   ],
   "source": [
    "# Mostrando datos Estandarizados\n",
    "print('X train:',X_train)\n",
    "print('---------------------------------------')\n",
    "print('X test:',X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
